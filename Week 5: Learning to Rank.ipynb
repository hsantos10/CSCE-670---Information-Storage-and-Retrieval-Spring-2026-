{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval: From Vector Space to Learning to Rank\n",
    "\n",
    "**Topics Covered:**\n",
    "1. Vector Space Model & TF-IDF\n",
    "2. Cosine Similarity\n",
    "3. Rocchio Algorithm (Relevance Feedback)\n",
    "4. k-Nearest Neighbors\n",
    "5. Evaluation Metrics (Precision, Recall, MAP, nDCG)\n",
    "6. Learning to Rank: Pointwise, Pairwise, Listwise\n",
    "7. Key Algorithms: RankSVM, RankNet, LambdaMART\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Expanded document collection for more interesting visualizations\n",
    "documents = [\n",
    "    \"Machine learning algorithms can learn from data\",\n",
    "    \"Deep learning uses neural networks with many layers\",\n",
    "    \"Natural language processing helps computers understand text\",\n",
    "    \"Computer vision enables machines to interpret images\",\n",
    "    \"Supervised learning requires labeled training data\",\n",
    "    \"Unsupervised learning finds patterns without labels\",\n",
    "    \"Reinforcement learning learns through trial and error\",\n",
    "    \"Neural networks are inspired by biological neurons\",\n",
    "    \"Gradient descent optimizes machine learning models\",\n",
    "    \"Convolutional networks excel at image recognition\",\n",
    "    \"Recurrent networks process sequential data effectively\",\n",
    "    \"Transfer learning reuses pretrained models\",\n",
    "    \"Ensemble methods combine multiple models\",\n",
    "    \"Decision trees make predictions using rules\",\n",
    "    \"Support vector machines find optimal boundaries\"\n",
    "]\n",
    "\n",
    "query = \"neural networks deep learning\"\n",
    "\n",
    "print(f\"Document Collection: {len(documents)} documents\")\n",
    "print(f\"Query: '{query}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vector Space Model & TF-IDF\n",
    "\n",
    "### Term Frequency (TF)\n",
    "$$TF(t, d) = \\text{count of term } t \\text{ in document } d$$\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "$$IDF(t) = \\log\\frac{N}{df(t)}$$\n",
    "- $N$ = total documents\n",
    "- $df(t)$ = documents containing term $t$\n",
    "\n",
    "### TF-IDF Weight\n",
    "$$w(t,d) = TF(t,d) \\times IDF(t)$$\n",
    "\n",
    "**Intuition:** High weight = term is frequent in this doc but rare overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display top terms per document\n",
    "print(\"Top 3 TF-IDF terms per document:\\n\")\n",
    "for i, doc in enumerate(documents[:5]):  # Show first 5\n",
    "    vec = tfidf_matrix[i].toarray().flatten()\n",
    "    top_indices = vec.argsort()[-3:][::-1]\n",
    "    top_terms = [(feature_names[idx], vec[idx]) for idx in top_indices]\n",
    "    print(f\"Doc {i+1}: {doc[:50]}...\")\n",
    "    print(f\"  Terms: {', '.join([f'{term}({score:.3f})' for term, score in top_terms])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cosine Similarity\n",
    "\n",
    "### Formula\n",
    "$$\\text{sim}(\\vec{q}, \\vec{d}) = \\frac{\\vec{q} \\cdot \\vec{d}}{||\\vec{q}|| \\cdot ||\\vec{d}||} = \\frac{\\sum q_i d_i}{\\sqrt{\\sum q_i^2} \\sqrt{\\sum d_i^2}}$$\n",
    "\n",
    "**Properties:**\n",
    "- Range: [0, 1] for text (since weights are non-negative)\n",
    "- 1 = identical, 0 = orthogonal\n",
    "- Length-normalized (long docs don't automatically score higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities\n",
    "query_vector = vectorizer.transform([query])\n",
    "similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "\n",
    "# Rank documents\n",
    "results_df = pd.DataFrame({\n",
    "    'Doc_ID': range(1, len(documents) + 1),\n",
    "    'Document': [doc[:60] + '...' if len(doc) > 60 else doc for doc in documents],\n",
    "    'Similarity': similarities\n",
    "}).sort_values('Similarity', ascending=False)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Top 10 Ranked Results:\")\n",
    "print(results_df.head(10).to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of all similarities\n",
    "sorted_idx = np.argsort(similarities)[::-1]\n",
    "colors = ['darkgreen' if sim > 0.3 else 'steelblue' if sim > 0.15 else 'lightgray' \n",
    "          for sim in similarities[sorted_idx]]\n",
    "ax1.barh(range(len(documents)), similarities[sorted_idx], color=colors)\n",
    "ax1.set_yticks(range(len(documents)))\n",
    "ax1.set_yticklabels([f'Doc{i+1}' for i in sorted_idx])\n",
    "ax1.set_xlabel('Cosine Similarity')\n",
    "ax1.set_title(f'Query-Document Similarity: \"{query}\"')\n",
    "ax1.axvline(x=0.3, color='red', linestyle='--', alpha=0.5, label='High relevance')\n",
    "ax1.axvline(x=0.15, color='orange', linestyle='--', alpha=0.5, label='Medium relevance')\n",
    "ax1.legend()\n",
    "\n",
    "# Distribution plot\n",
    "ax2.hist(similarities, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(similarities.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {similarities.mean():.3f}')\n",
    "ax2.set_xlabel('Similarity Score')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Similarity Scores')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rocchio Algorithm (Relevance Feedback)\n",
    "\n",
    "### Formula\n",
    "$$\\vec{q}_{new} = \\alpha \\vec{q}_{old} + \\beta \\frac{1}{|D_r|} \\sum_{\\vec{d} \\in D_r} \\vec{d} - \\gamma \\frac{1}{|D_{nr}|} \\sum_{\\vec{d} \\in D_{nr}} \\vec{d}$$\n",
    "\n",
    "**Parameters:**\n",
    "- $\\alpha = 1.0$ (original query weight)\n",
    "- $\\beta = 0.75$ (relevant docs weight)\n",
    "- $\\gamma = 0.15$ (non-relevant docs weight)\n",
    "\n",
    "**Intuition:** Move query towards relevant docs, away from non-relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio(q_vec, rel_vecs, nonrel_vecs, alpha=1.0, beta=0.75, gamma=0.15):\n",
    "    \"\"\"Apply Rocchio algorithm\"\"\"\n",
    "    q = np.array(q_vec)\n",
    "    centroid_r = np.mean(rel_vecs, axis=0) if len(rel_vecs) > 0 else np.zeros(q.shape)\n",
    "    centroid_nr = np.mean(nonrel_vecs, axis=0) if len(nonrel_vecs) > 0 else np.zeros(q.shape)\n",
    "    q_new = alpha * q + beta * centroid_r - gamma * centroid_nr\n",
    "    q_new[q_new < 0] = 0  # No negative weights\n",
    "    return q_new\n",
    "\n",
    "# User feedback based on initial results\n",
    "# Mark top results with \"neural\" or \"network\" as relevant\n",
    "relevant_ids = [1, 7, 9]  # Deep learning, Neural networks, Gradient descent\n",
    "nonrelevant_ids = [3, 5, 13]  # NLP, Unsupervised, Ensemble (less related)\n",
    "\n",
    "print(\"User Feedback:\")\n",
    "print(\"\\nRelevant Documents:\")\n",
    "for idx in relevant_ids:\n",
    "    print(f\"  Doc {idx+1}: {documents[idx]}\")\n",
    "print(\"\\nNon-Relevant Documents:\")\n",
    "for idx in nonrelevant_ids:\n",
    "    print(f\"  Doc {idx+1}: {documents[idx]}\")\n",
    "\n",
    "# Apply Rocchio\n",
    "q_new = rocchio(\n",
    "    query_vector.toarray(),\n",
    "    tfidf_matrix[relevant_ids].toarray(),\n",
    "    tfidf_matrix[nonrelevant_ids].toarray()\n",
    ")\n",
    "\n",
    "# Re-rank\n",
    "new_similarities = cosine_similarity(q_new.reshape(1, -1), tfidf_matrix)[0]\n",
    "\n",
    "# Compare rankings\n",
    "comparison = pd.DataFrame({\n",
    "    'Doc_ID': range(1, len(documents) + 1),\n",
    "    'Document': [doc[:50] + '...' for doc in documents],\n",
    "    'Before': similarities,\n",
    "    'After': new_similarities,\n",
    "    'Change': new_similarities - similarities\n",
    "})\n",
    "\n",
    "# Show biggest improvements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROCCHIO FEEDBACK RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBiggest Improvements:\")\n",
    "print(comparison.nlargest(5, 'Change')[['Doc_ID', 'Document', 'Before', 'After', 'Change']].to_string(index=False))\n",
    "print(\"\\nBiggest Declines:\")\n",
    "print(comparison.nsmallest(5, 'Change')[['Doc_ID', 'Document', 'Before', 'After', 'Change']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Rocchio impact\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Before vs After comparison\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(documents))\n",
    "width = 0.35\n",
    "bars1 = ax1.bar(x - width/2, similarities, width, label='Before Rocchio', alpha=0.8, color='steelblue')\n",
    "bars2 = ax1.bar(x + width/2, new_similarities, width, label='After Rocchio', alpha=0.8, color='coral')\n",
    "\n",
    "# Highlight feedback docs\n",
    "for idx in relevant_ids:\n",
    "    ax1.axvline(idx, color='green', alpha=0.2, linewidth=8, label='Relevant' if idx == relevant_ids[0] else '')\n",
    "for idx in nonrelevant_ids:\n",
    "    ax1.axvline(idx, color='red', alpha=0.2, linewidth=8, label='Non-relevant' if idx == nonrelevant_ids[0] else '')\n",
    "\n",
    "ax1.set_xlabel('Document ID')\n",
    "ax1.set_ylabel('Similarity Score')\n",
    "ax1.set_title('Similarity Scores: Before vs After Rocchio')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([f'{i+1}' for i in range(len(documents))])\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Change in ranking positions\n",
    "ax2 = axes[0, 1]\n",
    "before_rank = np.argsort(np.argsort(similarities)[::-1])\n",
    "after_rank = np.argsort(np.argsort(new_similarities)[::-1])\n",
    "rank_change = before_rank - after_rank\n",
    "\n",
    "colors_change = ['green' if c > 0 else 'red' if c < 0 else 'gray' for c in rank_change]\n",
    "ax2.barh(range(len(documents)), rank_change, color=colors_change, alpha=0.7)\n",
    "ax2.set_yticks(range(len(documents)))\n",
    "ax2.set_yticklabels([f'Doc{i+1}' for i in range(len(documents))])\n",
    "ax2.set_xlabel('Rank Change (positive = moved up)')\n",
    "ax2.set_title('Change in Ranking Position')\n",
    "ax2.axvline(0, color='black', linewidth=0.8)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Scatter plot: Before vs After\n",
    "ax3 = axes[1, 0]\n",
    "ax3.scatter(similarities, new_similarities, s=100, alpha=0.6, color='steelblue')\n",
    "for i in relevant_ids:\n",
    "    ax3.scatter(similarities[i], new_similarities[i], s=200, color='green', marker='o', \n",
    "               edgecolors='black', linewidths=2, label='Relevant' if i == relevant_ids[0] else '')\n",
    "for i in nonrelevant_ids:\n",
    "    ax3.scatter(similarities[i], new_similarities[i], s=200, color='red', marker='x', \n",
    "               linewidths=3, label='Non-relevant' if i == nonrelevant_ids[0] else '')\n",
    "\n",
    "# Add diagonal line (no change)\n",
    "max_val = max(similarities.max(), new_similarities.max())\n",
    "ax3.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='No change')\n",
    "\n",
    "ax3.set_xlabel('Similarity Before Rocchio')\n",
    "ax3.set_ylabel('Similarity After Rocchio')\n",
    "ax3.set_title('Before vs After: Each Point is a Document')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Vector space visualization (PCA)\n",
    "ax4 = axes[1, 1]\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "docs_2d = pca.fit_transform(tfidf_matrix.toarray())\n",
    "query_2d = pca.transform(query_vector.toarray())\n",
    "query_new_2d = pca.transform(q_new.reshape(1, -1))\n",
    "\n",
    "# Plot documents\n",
    "ax4.scatter(docs_2d[:, 0], docs_2d[:, 1], s=80, alpha=0.5, color='lightgray', label='Documents')\n",
    "for i in relevant_ids:\n",
    "    ax4.scatter(docs_2d[i, 0], docs_2d[i, 1], s=150, color='green', marker='o', \n",
    "               edgecolors='black', linewidths=2, label='Relevant' if i == relevant_ids[0] else '')\n",
    "for i in nonrelevant_ids:\n",
    "    ax4.scatter(docs_2d[i, 0], docs_2d[i, 1], s=150, color='red', marker='x', \n",
    "               linewidths=3, label='Non-relevant' if i == nonrelevant_ids[0] else '')\n",
    "\n",
    "# Plot queries\n",
    "ax4.scatter(query_2d[0, 0], query_2d[0, 1], s=300, color='blue', marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Original Query', zorder=5)\n",
    "ax4.scatter(query_new_2d[0, 0], query_new_2d[0, 1], s=300, color='orange', marker='*', \n",
    "           edgecolors='black', linewidths=2, label='New Query', zorder=5)\n",
    "\n",
    "# Arrow showing query movement\n",
    "ax4.annotate('', xy=query_new_2d[0], xytext=query_2d[0],\n",
    "            arrowprops=dict(arrowstyle='->', color='purple', lw=2))\n",
    "\n",
    "ax4.set_xlabel('PCA Component 1')\n",
    "ax4.set_ylabel('PCA Component 2')\n",
    "ax4.set_title('Vector Space Visualization (2D PCA Projection)')\n",
    "ax4.legend(loc='best', fontsize=8)\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Œ Key Observations:\")\n",
    "print(\"   â€¢ Green highlighted docs (relevant) moved UP in ranking\")\n",
    "print(\"   â€¢ Red highlighted docs (non-relevant) moved DOWN in ranking\")\n",
    "print(\"   â€¢ Query vector shifted towards relevant documents in vector space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. k-Nearest Neighbors (k-NN)\n",
    "\n",
    "**Concept:** Retrieve the $k$ most similar documents based on cosine similarity.\n",
    "\n",
    "This is what standard search does when you ask for \"top k results\"!\n",
    "\n",
    "### Algorithm\n",
    "1. Compute similarity between query and all documents\n",
    "2. Sort documents by similarity (descending)\n",
    "3. Return top $k$ documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(query_text, k=5, return_scores=False):\n",
    "    \"\"\"Perform k-NN search\"\"\"\n",
    "    q_vec = vectorizer.transform([query_text])\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix)[0]\n",
    "    top_k_idx = np.argsort(sims)[::-1][:k]\n",
    "    \n",
    "    results = []\n",
    "    print(f\"\\nk-NN Search Results (k={k}):\")\n",
    "    print(f\"Query: '{query_text}'\\n\")\n",
    "    print(f\"{'Rank':<6} {'Doc ID':<8} {'Score':<10} Document\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for rank, idx in enumerate(top_k_idx, 1):\n",
    "        print(f\"{rank:<6} {idx+1:<8} {sims[idx]:<10.4f} {documents[idx][:60]}...\")\n",
    "        results.append((idx, sims[idx]))\n",
    "    \n",
    "    if return_scores:\n",
    "        return top_k_idx, sims[top_k_idx]\n",
    "    return top_k_idx\n",
    "\n",
    "# Test with different k values\n",
    "k_values = [3, 5, 10]\n",
    "for k in k_values:\n",
    "    knn_search(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive k-NN visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Distance/Similarity visualization in 2D space\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "pca = PCA(n_components=2)\n",
    "docs_2d = pca.fit_transform(tfidf_matrix.toarray())\n",
    "query_2d = pca.transform(query_vector.toarray())\n",
    "\n",
    "# Plot all documents\n",
    "ax1.scatter(docs_2d[:, 0], docs_2d[:, 1], s=100, alpha=0.4, color='lightblue', \n",
    "           edgecolors='black', linewidths=0.5, label='All Documents')\n",
    "\n",
    "# Highlight k-nearest neighbors for different k values\n",
    "k_vals = [3, 5, 8]\n",
    "colors_k = ['red', 'orange', 'yellow']\n",
    "sizes_k = [300, 200, 150]\n",
    "\n",
    "for k, color, size in zip(k_vals, colors_k, sizes_k):\n",
    "    top_k_idx, _ = knn_search(query, k=k, return_scores=True)\n",
    "    ax1.scatter(docs_2d[top_k_idx, 0], docs_2d[top_k_idx, 1], \n",
    "               s=size, alpha=0.6, color=color, edgecolors='black', linewidths=2,\n",
    "               label=f'Top-{k} Neighbors', zorder=3)\n",
    "\n",
    "# Plot query\n",
    "ax1.scatter(query_2d[0, 0], query_2d[0, 1], s=500, color='blue', marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Query', zorder=5)\n",
    "\n",
    "# Draw lines to nearest neighbors\n",
    "top_3_idx, _ = knn_search(query, k=3, return_scores=True)\n",
    "for idx in top_3_idx:\n",
    "    ax1.plot([query_2d[0, 0], docs_2d[idx, 0]], \n",
    "            [query_2d[0, 1], docs_2d[idx, 1]], \n",
    "            'k--', alpha=0.3, linewidth=1)\n",
    "\n",
    "# Annotate documents\n",
    "for i, (x, y) in enumerate(docs_2d):\n",
    "    ax1.annotate(f'{i+1}', (x, y), fontsize=8, ha='center', va='center')\n",
    "\n",
    "ax1.set_xlabel('PCA Component 1', fontsize=12)\n",
    "ax1.set_ylabel('PCA Component 2', fontsize=12)\n",
    "ax1.set_title('k-NN in 2D Vector Space (PCA Projection)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# 2. Similarity scores for different k values\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "k_comparison = [3, 5, 10]\n",
    "for k in k_comparison:\n",
    "    top_k_idx, top_k_scores = knn_search(query, k=k, return_scores=True)\n",
    "    ax2.plot(range(1, k+1), top_k_scores, 'o-', linewidth=2, markersize=8, label=f'k={k}')\n",
    "\n",
    "ax2.set_xlabel('Rank Position')\n",
    "ax2.set_ylabel('Cosine Similarity')\n",
    "ax2.set_title('Similarity Decay by Rank')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Precision@k for different k values\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "# Assume docs with similarity > 0.2 are relevant (for demo)\n",
    "relevant_threshold = 0.2\n",
    "k_range = range(1, 16)\n",
    "precisions = []\n",
    "\n",
    "for k in k_range:\n",
    "    top_k_idx, top_k_scores = knn_search(query, k=k, return_scores=True)\n",
    "    relevant_retrieved = sum(score > relevant_threshold for score in top_k_scores)\n",
    "    precision = relevant_retrieved / k\n",
    "    precisions.append(precision)\n",
    "\n",
    "ax3.plot(k_range, precisions, 'o-', linewidth=2, markersize=6, color='darkgreen')\n",
    "ax3.set_xlabel('k (Number of Retrieved Documents)')\n",
    "ax3.set_ylabel('Precision@k')\n",
    "ax3.set_title('Precision vs k')\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_ylim([0, 1.1])\n",
    "\n",
    "# 4. Distance distribution\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "all_sims = similarities\n",
    "ax4.hist(all_sims, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "\n",
    "# Mark k-NN thresholds\n",
    "for k, color in [(3, 'red'), (5, 'orange'), (10, 'yellow')]:\n",
    "    top_k_idx, top_k_scores = knn_search(query, k=k, return_scores=True)\n",
    "    threshold = top_k_scores[-1]\n",
    "    ax4.axvline(threshold, color=color, linestyle='--', linewidth=2, label=f'k={k} threshold')\n",
    "\n",
    "ax4.set_xlabel('Cosine Similarity')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Distribution of All Similarities')\n",
    "ax4.legend(fontsize=8)\n",
    "\n",
    "# 5. Heatmap of similarity matrix (query vs all docs)\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "top_10_idx, _ = knn_search(query, k=10, return_scores=True)\n",
    "subset_matrix = sim_matrix[np.ix_(top_10_idx, top_10_idx)]\n",
    "\n",
    "im = ax5.imshow(subset_matrix, cmap='YlOrRd', aspect='auto')\n",
    "ax5.set_xticks(range(10))\n",
    "ax5.set_yticks(range(10))\n",
    "ax5.set_xticklabels([f'Doc{i+1}' for i in top_10_idx])\n",
    "ax5.set_yticklabels([f'Doc{i+1}' for i in top_10_idx])\n",
    "ax5.set_title('Similarity Matrix: Top-10 Documents (to each other)')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax5)\n",
    "cbar.set_label('Cosine Similarity')\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        text = ax5.text(j, i, f'{subset_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "plt.suptitle(f'k-Nearest Neighbors Analysis for Query: \"{query}\"', \n",
    "            fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Œ Key Observations:\")\n",
    "print(\"   â€¢ Documents closer to query in vector space have higher similarity\")\n",
    "print(\"   â€¢ Similarity decreases as rank increases (distance from query grows)\")\n",
    "print(\"   â€¢ Precision@k shows how many of top-k results are relevant\")\n",
    "print(\"   â€¢ Some nearest neighbors are also similar to each other (clusters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive comparison: Multiple queries\n",
    "test_queries = [\n",
    "    \"neural networks deep learning\",\n",
    "    \"supervised machine learning algorithms\",\n",
    "    \"computer vision image processing\"\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, test_q in enumerate(test_queries):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Compute similarities\n",
    "    q_vec = vectorizer.transform([test_q])\n",
    "    sims = cosine_similarity(q_vec, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get top-5\n",
    "    top_5 = np.argsort(sims)[::-1][:5]\n",
    "    \n",
    "    # Plot\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, 5))\n",
    "    bars = ax.barh(range(5), sims[top_5][::-1], color=colors[::-1])\n",
    "    ax.set_yticks(range(5))\n",
    "    ax.set_yticklabels([f'Doc{i+1}' for i in top_5[::-1]])\n",
    "    ax.set_xlabel('Similarity')\n",
    "    ax.set_title(f'Query: \"{test_q[:30]}...\"', fontsize=10)\n",
    "    ax.set_xlim([0, max(sims) * 1.1])\n",
    "    \n",
    "    # Add values\n",
    "    for i, (bar, val) in enumerate(zip(bars, sims[top_5][::-1])):\n",
    "        ax.text(val + 0.01, i, f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('k-NN Results for Different Queries (k=5)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics\n",
    "\n",
    "### Precision & Recall\n",
    "$$P = \\frac{|\\text{Relevant} \\cap \\text{Retrieved}|}{|\\text{Retrieved}|}$$\n",
    "$$R = \\frac{|\\text{Relevant} \\cap \\text{Retrieved}|}{|\\text{Relevant}|}$$\n",
    "\n",
    "### F-Measure\n",
    "$$F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R}$$\n",
    "\n",
    "### Average Precision (AP)\n",
    "$$AP = \\frac{1}{|R|} \\sum_{k=1}^{n} P(k) \\cdot rel(k)$$\n",
    "\n",
    "### Mean Average Precision (MAP)\n",
    "$$MAP = \\frac{1}{|Q|} \\sum_{q=1}^{|Q|} AP(q)$$\n",
    "\n",
    "### Normalized Discounted Cumulative Gain (nDCG)\n",
    "$$DCG@k = \\sum_{i=1}^{k} \\frac{2^{rel_i} - 1}{\\log_2(i + 1)}$$\n",
    "$$nDCG@k = \\frac{DCG@k}{IDCG@k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(retrieved, relevant):\n",
    "    tp = len(set(retrieved) & set(relevant))\n",
    "    p = tp / len(retrieved) if retrieved else 0\n",
    "    r = tp / len(relevant) if relevant else 0\n",
    "    return p, r\n",
    "\n",
    "def average_precision(ranked_results, relevant_docs):\n",
    "    relevant_set = set(relevant_docs)\n",
    "    precisions = []\n",
    "    num_relevant = 0\n",
    "    \n",
    "    for i, doc_id in enumerate(ranked_results, 1):\n",
    "        if doc_id in relevant_set:\n",
    "            num_relevant += 1\n",
    "            precisions.append(num_relevant / i)\n",
    "    \n",
    "    return sum(precisions) / len(relevant_set) if relevant_set else 0\n",
    "\n",
    "def ndcg(relevances, k=None):\n",
    "    if k: relevances = relevances[:k]\n",
    "    dcg = sum((2**rel - 1) / np.log2(i + 2) for i, rel in enumerate(relevances))\n",
    "    ideal = sorted(relevances, reverse=True)\n",
    "    idcg = sum((2**rel - 1) / np.log2(i + 2) for i, rel in enumerate(ideal))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# Example\n",
    "retrieved = [3, 7, 1, 5, 2]\n",
    "relevant = [1, 2, 3, 5]\n",
    "\n",
    "p, r = precision_recall(retrieved, relevant)\n",
    "ap = average_precision(retrieved, relevant)\n",
    "\n",
    "print(f\"Retrieved: {retrieved}\")\n",
    "print(f\"Relevant:  {relevant}\")\n",
    "print(f\"\\nPrecision: {p:.3f}\")\n",
    "print(f\"Recall:    {r:.3f}\")\n",
    "print(f\"F1:        {2*p*r/(p+r):.3f}\")\n",
    "print(f\"AP:        {ap:.3f}\")\n",
    "\n",
    "# nDCG example\n",
    "relevances = [3, 2, 3, 0, 1, 2]  # Graded relevance (0-3)\n",
    "print(f\"\\nnDCG@5:    {ndcg(relevances, k=5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Introduction to Learning to Rank (LTR)\n",
    "\n",
    "### Evolution\n",
    "**Before:** Manual weights\n",
    "```\n",
    "score = 0.5Ã—TF-IDF + 0.3Ã—PageRank + 0.2Ã—URLDepth\n",
    "```\n",
    "\n",
    "**After:** Machine Learning\n",
    "```\n",
    "Learn weights w from training data:\n",
    "score = wâ‚Ã—TF-IDF + wâ‚‚Ã—PageRank + wâ‚ƒÃ—URLDepth + ...\n",
    "```\n",
    "\n",
    "### Training Data Sources\n",
    "- **Explicit:** Human relevance judgments (0-4 scale)\n",
    "- **Implicit:** Clickthrough logs (clicked = more relevant)\n",
    "\n",
    "### Why LTR?\n",
    "âœ… Handles 100+ features automatically  \n",
    "âœ… Learns from user behavior  \n",
    "âœ… Outperforms manual tuning  \n",
    "âœ… Enables personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Three Approaches to LTR\n",
    "\n",
    "### Pointwise: Predict Relevance Score\n",
    "- **Input:** Features of (query, doc)\n",
    "- **Output:** Relevance score (e.g., 0-4)\n",
    "- **Method:** Regression or classification\n",
    "- **Example:** Linear regression, neural network\n",
    "\n",
    "### Pairwise: Predict Relative Order\n",
    "- **Input:** Features of (query, docâ‚, docâ‚‚)\n",
    "- **Output:** Which doc should rank higher?\n",
    "- **Method:** Classification on pairs\n",
    "- **Example:** RankSVM, RankNet, LambdaRank\n",
    "\n",
    "### Listwise: Optimize Entire Ranking\n",
    "- **Input:** Features of (query, [docâ‚, docâ‚‚, ..., docâ‚™])\n",
    "- **Output:** Optimal ordering\n",
    "- **Method:** Directly optimize IR metric\n",
    "- **Example:** ListNet, AdaRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison visualization\n",
    "approaches = ['Pointwise', 'Pairwise', 'Listwise']\n",
    "metrics = {\n",
    "    'Simplicity': [9, 6, 3],\n",
    "    'Performance': [6, 8, 9],\n",
    "    'Training Speed': [9, 6, 3],\n",
    "    'Direct Optimization': [3, 6, 9]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(metrics, index=approaches)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df.plot(kind='bar', ax=ax)\n",
    "ax.set_ylabel('Score (0-10)')\n",
    "ax.set_title('Comparison of LTR Approaches')\n",
    "ax.set_xticklabels(approaches, rotation=0)\n",
    "ax.legend(title='Aspect')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pointwise Approach\n",
    "\n",
    "### Classification: Binary Relevance\n",
    "$$y = f(\\vec{x}) \\in \\{0, 1\\}$$\n",
    "\n",
    "### Regression: Graded Relevance\n",
    "$$y = f(\\vec{x}) \\in [0, 4]$$\n",
    "\n",
    "**Pros:** Simple, uses standard ML algorithms  \n",
    "**Cons:** Doesn't optimize for ranking, treats docs independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Features: [tfidf, bm25, pagerank, doc_len, query_coverage]\n",
    "X_train = np.array([\n",
    "    [0.9, 0.95, 0.8, 130, 1.0],\n",
    "    [0.8, 0.85, 0.7, 110, 0.9],\n",
    "    [0.5, 0.6, 0.4, 80, 0.5],\n",
    "    [0.3, 0.4, 0.2, 60, 0.3],\n",
    "    [0.1, 0.15, 0.05, 30, 0.1],\n",
    "])\n",
    "y_train = np.array([4, 3, 2, 1, 0])  # Relevance grades\n",
    "\n",
    "# Train pointwise model\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "X_test = np.array([\n",
    "    [0.85, 0.88, 0.75, 115, 0.92],\n",
    "    [0.4, 0.5, 0.3, 70, 0.4],\n",
    "    [0.92, 0.96, 0.85, 135, 0.98],\n",
    "])\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Pointwise Predictions (Relevance Scores):\")\n",
    "for i, score in enumerate(predictions, 1):\n",
    "    print(f\"Doc {i}: {score:.2f}\")\n",
    "\n",
    "# Rank by score\n",
    "ranked = np.argsort(predictions)[::-1]\n",
    "print(\"\\nRanking:\", [f\"Doc{i+1}\" for i in ranked])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pairwise Approach: RankSVM\n",
    "\n",
    "### Key Idea\n",
    "Learn from preference pairs: $(d_i, d_j)$ where $d_i \\succ d_j$\n",
    "\n",
    "### Optimization\n",
    "$$\\min_{\\vec{w}} \\frac{1}{2}||\\vec{w}||^2 + C\\sum_{(i,j)} \\xi_{ij}$$\n",
    "\n",
    "Subject to:\n",
    "$$\\vec{w} \\cdot (\\vec{x_i} - \\vec{x_j}) \\geq 1 - \\xi_{ij}$$\n",
    "\n",
    "**Intuition:** Learn weight vector $\\vec{w}$ such that more relevant docs score higher\n",
    "\n",
    "### Training Data from Clicks\n",
    "If user clicks doc at position 5 but not position 2:\n",
    "$$d_5 \\succ d_2 \\text{ (generate training pair)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairwise training data\n",
    "def create_pairs(X, y):\n",
    "    \"\"\"Generate preference pairs from pointwise data\"\"\"\n",
    "    pairs_X, pairs_y = [], []\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X)):\n",
    "            if y[i] > y[j]:\n",
    "                pairs_X.append(X[i] - X[j])\n",
    "                pairs_y.append(1)\n",
    "    return np.array(pairs_X), np.array(pairs_y)\n",
    "\n",
    "X_pairs, y_pairs = create_pairs(X_train, y_train)\n",
    "print(f\"Generated {len(X_pairs)} preference pairs from {len(X_train)} documents\")\n",
    "print(f\"Example pair (difference vector): {X_pairs[0]}\")\n",
    "\n",
    "# Train SVM on pairs\n",
    "from sklearn.svm import LinearSVC\n",
    "ranksvm = LinearSVC(random_state=42)\n",
    "ranksvm.fit(X_pairs, y_pairs)\n",
    "print(\"\\nâœ… RankSVM trained on pairwise preferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Pairwise Approach: RankNet\n",
    "\n",
    "### Neural Network Architecture\n",
    "```\n",
    "Input (features) â†’ Hidden Layers â†’ Output (score)\n",
    "```\n",
    "\n",
    "### Pairwise Probability\n",
    "$$P(d_i \\succ d_j) = \\frac{1}{1 + e^{-\\sigma(s_i - s_j)}}$$\n",
    "\n",
    "Where $s_i = f_{NN}(\\vec{x_i})$ is the neural network score\n",
    "\n",
    "### Loss Function (Cross-Entropy)\n",
    "$$L = -\\bar{P}_{ij}\\log P_{ij} - (1-\\bar{P}_{ij})\\log(1 - P_{ij})$$\n",
    "\n",
    "**Training:** Use gradient descent to minimize loss over all pairs\n",
    "\n",
    "**Advantage:** Smooth, differentiable, scalable to large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RankNet probability calculation\n",
    "def ranknet_prob(score_i, score_j, sigma=1.0):\n",
    "    return 1.0 / (1.0 + np.exp(-sigma * (score_i - score_j)))\n",
    "\n",
    "# Example scores\n",
    "scores = [0.9, 0.7, 0.5, 0.2]\n",
    "\n",
    "print(\"RankNet Pairwise Probabilities P(i > j):\\n\")\n",
    "print(\"     \" + \"  \".join([f\"D{i+1}\" for i in range(len(scores))]))\n",
    "for i in range(len(scores)):\n",
    "    row = f\"D{i+1}  \"\n",
    "    for j in range(len(scores)):\n",
    "        if i == j:\n",
    "            row += \" -   \"\n",
    "        else:\n",
    "            prob = ranknet_prob(scores[i], scores[j])\n",
    "            row += f\"{prob:.2f} \"\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nInterpretation: P(D1 > D4) = 0.99 (very confident D1 should rank higher)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. LambdaRank & LambdaMART\n",
    "\n",
    "### Problem with RankNet\n",
    "All pairwise errors weighted equally, but **top-of-ranking errors matter more!**\n",
    "\n",
    "### LambdaRank Solution\n",
    "Scale gradients by change in IR metric:\n",
    "\n",
    "$$\\lambda_{ij} = \\frac{\\partial L}{\\partial s_i} \\cdot |\\Delta nDCG_{ij}|$$\n",
    "\n",
    "Where $\\Delta nDCG_{ij}$ = change in nDCG if we swap docs $i$ and $j$\n",
    "\n",
    "### LambdaMART\n",
    "**Combines:** LambdaRank + Gradient Boosted Trees (MART)\n",
    "\n",
    "**Architecture:**\n",
    "- Ensemble of decision trees\n",
    "- Each tree trained on lambda gradients\n",
    "- Final score = $\\sum_t \\text{tree}_t(\\vec{x})$\n",
    "\n",
    "**Performance:** Winner of Yahoo! LTR Challenge 2010, industry standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate impact of ranking position on nDCG\n",
    "def show_position_importance():\n",
    "    base_relevance = [3, 2, 1, 1, 0, 0, 0]\n",
    "    \n",
    "    # Swap highly relevant doc from position 1 to 3\n",
    "    swap_early = base_relevance.copy()\n",
    "    swap_early[0], swap_early[2] = swap_early[2], swap_early[0]\n",
    "    \n",
    "    # Swap low relevant doc from position 5 to 7\n",
    "    swap_late = base_relevance.copy()\n",
    "    swap_late[4], swap_late[6] = swap_late[6], swap_late[4]\n",
    "    \n",
    "    ndcg_base = ndcg(base_relevance)\n",
    "    ndcg_early = ndcg(swap_early)\n",
    "    ndcg_late = ndcg(swap_late)\n",
    "    \n",
    "    print(\"Impact of Ranking Position on nDCG:\\n\")\n",
    "    print(f\"Original ranking:     nDCG = {ndcg_base:.3f}\")\n",
    "    print(f\"Swap positions 1â†”3:   nDCG = {ndcg_early:.3f} (Î” = {ndcg_early-ndcg_base:.3f})\")\n",
    "    print(f\"Swap positions 5â†”7:   nDCG = {ndcg_late:.3f} (Î” = {ndcg_late-ndcg_base:.3f})\")\n",
    "    print(\"\\nðŸ“Œ Top-position errors hurt nDCG more â†’ LambdaRank focuses there!\")\n",
    "\n",
    "show_position_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparison & Best Practices\n",
    "\n",
    "### Algorithm Comparison\n",
    "\n",
    "| Algorithm | Type | Pros | Cons | Use Case |\n",
    "|-----------|------|------|------|----------|\n",
    "| **Linear Regression** | Pointwise | Simple | Doesn't optimize ranking | Baseline |\n",
    "| **RankSVM** | Pairwise | Good with clicks | Many pairs | Clickthrough data |\n",
    "| **RankNet** | Pairwise | Scalable | Doesn't prioritize top | Large-scale |\n",
    "| **LambdaRank** | Pairwise | Direct metric opt. | Complex | High performance |\n",
    "| **LambdaMART** | Pairwise | State-of-art | Training time | Production |\n",
    "\n",
    "### Feature Engineering Tips\n",
    "**Query-Doc Features:** TF-IDF, BM25, cosine similarity  \n",
    "**Doc Features:** PageRank, length, freshness, authority  \n",
    "**Query Features:** Length, type, popularity  \n",
    "**URL Features:** Depth, domain authority, HTTPS  \n",
    "\n",
    "### Public Datasets\n",
    "- **LETOR:** Microsoft Research benchmark (MQ2007, MQ2008)\n",
    "- **MSLR-WEB:** Large-scale Bing data (10K-30K queries)\n",
    "- **Yahoo! C14:** 30K queries, 700+ features\n",
    "- **Yandex:** Personalized search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Timeline\n",
    "years = [2002, 2005, 2006, 2010, 2015, 2020]\n",
    "algorithms = ['RankSVM', 'RankNet', 'LambdaRank', 'LambdaMART', 'Neural LTR', 'BERT Rankers']\n",
    "ax1.plot(years, range(len(years)), 'o-', linewidth=2, markersize=10)\n",
    "for i, (year, algo) in enumerate(zip(years, algorithms)):\n",
    "    ax1.text(year, i, f' {algo}', va='center', fontsize=10)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_title('Evolution of Learning to Rank')\n",
    "ax1.set_yticks([])\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Performance vs Complexity\n",
    "complexity = [3, 5, 7, 8, 6, 9]\n",
    "performance = [6, 7, 8, 9, 8, 9.5]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(algorithms)))\n",
    "\n",
    "for i, (c, p, algo, col) in enumerate(zip(complexity, performance, algorithms, colors)):\n",
    "    ax2.scatter(c, p, s=200, color=col, alpha=0.7)\n",
    "    ax2.annotate(algo, (c, p), fontsize=8, ha='center')\n",
    "\n",
    "ax2.set_xlabel('Complexity')\n",
    "ax2.set_ylabel('Performance')\n",
    "ax2.set_title('Performance vs Complexity Trade-off')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways\n",
    "\n",
    "### Classical IR\n",
    "âœ… **TF-IDF:** Balance term frequency with document frequency  \n",
    "âœ… **Cosine Similarity:** Length-normalized vector similarity  \n",
    "âœ… **Rocchio:** Query refinement using relevance feedback  \n",
    "âœ… **k-NN:** Retrieve k most similar documents based on distance\n",
    "\n",
    "### Evaluation\n",
    "âœ… **Precision/Recall:** Basic quality measures  \n",
    "âœ… **MAP:** Average precision across queries  \n",
    "âœ… **nDCG:** Considers position + graded relevance  \n",
    "\n",
    "### Learning to Rank\n",
    "âœ… **Pointwise:** Predict individual scores (simple but suboptimal)  \n",
    "âœ… **Pairwise:** Learn relative order (industry standard)  \n",
    "âœ… **LambdaMART:** State-of-the-art, used in production  \n",
    "\n",
    "### Modern Trends (2024)\n",
    "ðŸ”¥ **Transformer Models:** BERT, T5 for semantic matching  \n",
    "ðŸ”¥ **Neural Rankers:** End-to-end deep learning  \n",
    "ðŸ”¥ **Personalization:** User-specific ranking functions  \n",
    "ðŸ”¥ **Multi-task Learning:** Joint optimization of multiple objectives  \n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "- Manning et al., \"Introduction to Information Retrieval\" (2008)\n",
    "- Liu, \"Learning to Rank for Information Retrieval\" (2011)\n",
    "- Burges et al., \"Learning to Rank using Gradient Descent\" (RankNet, 2005)\n",
    "- Wu et al., \"Adapting Boosting for Information Retrieval\" (LambdaMART, 2010)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
